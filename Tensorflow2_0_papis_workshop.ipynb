{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow2.0_papis_workshop.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sthalles/tensorflow2.0-papis-workshop/blob/master/Tensorflow2_0_papis_workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_Fpon_frLlk",
        "colab_type": "text"
      },
      "source": [
        "# Everything you need to know about Tensorflow 2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4AL8ClyNMQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Installing and loading libraries\n",
        "!pip install tensorflow-gpu==2.0.0-beta1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6onnL0mvxoSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download and install keras-tuner\n",
        "!git clone https://github.com/keras-team/keras-tuner.git\n",
        "!pip install ./keras-tuner"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voiTwjZ9rLB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import libraries\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Tensorflow datasets\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "print(tf.__version__)\n",
        "\n",
        "import time\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.python.keras.callbacks import TensorBoard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6hyVqrHZZ3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8,8))\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXAvW1MIm89g",
        "colab_type": "text"
      },
      "source": [
        "## What is Tensorflow\n",
        "\n",
        "- Tensorflow is a general purpose high-performance computing library.\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1s4d6Na9fSCGjF_zyVT4p5fmLFnxCa_mS)\n",
        "\n",
        "- OpenSourced by Google in 2015\n",
        "\n",
        "- Very Popular Machine Learning Lib.\n",
        "  - **130K stars and 58k commits on Github.**\n",
        "\n",
        "- From a Neural Network based lib to a robust ML ecosystem.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJu2WiMdczkI",
        "colab_type": "text"
      },
      "source": [
        "## TF 1.x vs TF 2.0\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1xv51KueUja9A-jNpjBswlRSOGp8tGGFx)\n",
        "\n",
        "You could define some variables and assign values to them, but you couldn't really use them.\n",
        "\n",
        "### Tensorflow 1.x\n",
        "- tf.layers\n",
        "- tf.slim\n",
        "- tf.layers.contrib\n",
        "- tf.keras\n",
        "-tf.estimators\n",
        "    \n",
        "### Tensorflow 2.0\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1u-Hp8X9QbBDwoblNVB-syKj8DmEY2fCi)\n",
        "\n",
        "- Eager Execution By Default\n",
        "  - Code looks a lot like NumPy programming\n",
        "  - Do not need to worry about **sessions**, **placeholders**, **feed_dict**, etc.\n",
        "- API Cleanup\n",
        "- tf.keras as the default high-level API\n",
        "- Standardized was of saving models (SavedModel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI3qnpuQrrGC",
        "colab_type": "text"
      },
      "source": [
        "## Beginners API\n",
        "\n",
        "- Keras is a set of layers that describes how to build neural networks using a clear standard.\n",
        "- Install Tensorflow using pip and get the full Keras API\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-h2rXPXttvhE",
        "colab": {}
      },
      "source": [
        "# load the date using keras datasets\n",
        "\n",
        "# Choose between mnist and fashing_mnist\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "# load the data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# check some statistics\n",
        "IMAGE_HEIGHT, IMAGE_WIDTH = x_train.shape[1:3]\n",
        "print(\"# of train examples:\", x_train.shape[0])\n",
        "print(\"# of test examples:\", x_test.shape[0])\n",
        "print(\"Image shape:\", x_train[0].shape)\n",
        "print(\"Pixel value interval:\", np.min(x_train), np.max(x_train))\n",
        "print(\"Train shape:\",x_train.shape)\n",
        "print(\"Test shape:\",x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upDZLC6pTiA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalize the data\n",
        "train_mean = np.mean(x_train)\n",
        "train_std = np.std(x_train)\n",
        "x_train = (x_train - train_mean) / train_std\n",
        "x_test = (x_test - train_mean) / train_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yLuT6LqxhZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# visualize some of the examples\n",
        "fig, axs = plt.subplots(nrows=3, ncols=6, constrained_layout=False, figsize=(12,4))\n",
        "for i, ax in enumerate(axs.flat):\n",
        "  ax.imshow(x_train[i], cmap=\"gray\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDIc8ykVLuLz",
        "colab_type": "text"
      },
      "source": [
        "## Begginer API\n",
        "\n",
        "##  Keras Sequential API \n",
        "- The Sequential API defines a Neural Network as a stack of layers\n",
        "- Very easy to define a model and to add new layers\n",
        "- You a really defining a data structure\n",
        "- Minimize errors in the model definition\n",
        "- Much easier to debug\n",
        "\n",
        "## Get your hands dirty\n",
        "- Define your own Neural Net\n",
        "- Specify the # of units for the hidden layer\n",
        "- Do not forget the **number of classes**\n",
        "- Try to add more hidden layers\n",
        "  - **Dense()**\n",
        "  -  **Dropout()**\n",
        "  - **BatchNormalization()**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkj96hCfc1O_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tensorflow keras layers\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, Conv2D, AveragePooling2D, MaxPool2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOwDt94urLEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(Flatten(input_shape=(IMAGE_HEIGHT,IMAGE_WIDTH)))\n",
        "model.add(Dense(units=..., activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(units=..., activation='relu'))\n",
        "model.add(Dense(units=10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BXHP_0YqsfT",
        "colab_type": "text"
      },
      "source": [
        "## Configures the model for training.\n",
        "\n",
        "- **optimizer**: String (name of optimizer) or optimizer instance. e.g. adam, rmsprob\n",
        "- **metrics**:  List of metrics to be evaluated by the model during training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zIm1V-6rLHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configures the model for training.\n",
        "# Define the model optimizer, the loss function and the accuracy metrics\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-79GNR6A-wY4",
        "colab_type": "text"
      },
      "source": [
        "## Setting up TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmj2cTqO-v0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "# create the tensorboard callback\n",
        "tensorboard = TensorBoard(log_dir='logs/{}'.format(time.time()), histogram_freq=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oseXrnZauCQW",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4sa-8G0voAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train the model\n",
        "model.fit(x=x_train, \n",
        "          y=y_train, \n",
        "          epochs=2, \n",
        "          validation_data=(x_test, y_test), \n",
        "          callbacks=[tensorboard])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDXj0t4WArDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# launch TensorBoard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDk6mHAqx8I5",
        "colab_type": "text"
      },
      "source": [
        "## Keras-Tuner\n",
        "\n",
        "- **Keras-tuner** is a dedicated library for hyper-parameter tuning of Keras models. \n",
        "- The lib is in **pre-alpha** status, but works fine on Colab with tf.keras and Tensorflow 2.0 beta. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBIwO92yx6ns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from kerastuner.tuners import RandomSearch\n",
        "\n",
        "\n",
        "def build_model(hp):\n",
        "  # define the hyper parameter ranges for the learning rate, dropout and hidden unit\n",
        "  hp_units = hp.Range('units', min_value=32, max_value=128, step=32)\n",
        "  hp_lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "  hp_dropout = hp.Choice('dropout', values=[0.1,0.2,0.3])\n",
        "\n",
        "  # build a Sequential model\n",
        "  model = keras.Sequential()\n",
        "  model.add(Flatten(input_shape=(IMAGE_HEIGHT,IMAGE_WIDTH)))\n",
        "  model.add(Dense(units=hp_units, activation='relu'))\n",
        "  model.add(Dropout(hp_dropout))\n",
        "  model.add(Dense(units=32, activation='relu'))\n",
        "  model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "  # compile and return the model\n",
        "  model.compile(optimizer=keras.optimizers.Adam(hp_lr),\n",
        "      loss='sparse_categorical_crossentropy',\n",
        "      metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGuJtipLzk9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a Random Search tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy', # define the metric to be optimized over\n",
        "    max_trials=3,\n",
        "    executions_per_trial=1,\n",
        "    directory='my_logs') # define the output log/checkpoints folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0ZFQLhNzjcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# start hyper-parameter optmizatin search\n",
        "tuner.search(x_train, y_train,\n",
        "             epochs=2,\n",
        "             validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCDRarJF5XPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You can print a summary of the search space:\n",
        "tuner.results_summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7vcR3Mx5jDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the best model\n",
        "model = tuner.get_best_models(num_models=1)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz9urtAXuEPn",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89d4A0NjXR9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test your model using the test data\n",
        "predictions = model.predict(x_test)\n",
        "predictions = tf.argmax(predictions, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw6iAvhdZfBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check the confusion matrix\n",
        "classes=[\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
        "plot_confusion_matrix(y_test, predictions, classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMbvCaGJrxJw",
        "colab_type": "text"
      },
      "source": [
        "## Expert API\n",
        "\n",
        "## Model Subclassing\n",
        "\n",
        "- Feels like Python Object Oriented programming (Inspired by Chainer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGdjjXZLK1cU",
        "colab_type": "text"
      },
      "source": [
        "## Data Loading and Transformation\n",
        "\n",
        "- Tensorflow datasets provide many, ready to use, datasets\n",
        "- For this demo, you can use a Vision classification dataset like:\n",
        "   - cifar10\n",
        "   - cifar100\n",
        "   - MNIST "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYKIzMvYlaWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# See available datasets\n",
        "print(tfds.list_builders())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYZYzUxI24fq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# choose a dataset\n",
        "# - horses_or_humans\n",
        "# - cifar10\n",
        "# - cifar100\n",
        "# - caltech101\n",
        "\n",
        "DATASET_NAME = 'cifar10'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-ALlE6w2HA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_images(features):\n",
        "  image, label = features[\"image\"], features[\"label\"]\n",
        "  return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4Qee--gmVku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scalling(image, label, height=32, width=32):\n",
        "  return tf.image.resize(image, [height, width]), label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-5tL1aum6s-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  return image/255., label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdqRiXmbo527",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE=128\n",
        "EPOCHS=2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPgF7ULQ0HgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Construct a tf.data.Dataset\n",
        "# tf.data.DataSet acts as an ETL (Extract Transform Load) tool\n",
        "train_dataset = tfds.load(name=DATASET_NAME, split=tfds.Split.TRAIN)\n",
        "\n",
        "# Build your input pipeline\n",
        "train_dataset = train_dataset.map(read_images)\n",
        "train_dataset = train_dataset.map(normalize)\n",
        "train_dataset = train_dataset.shuffle(1024)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "train_dataset = train_dataset.repeat(1)\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1tcIigo14lf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Construct a testing tf.data.Dataset\n",
        "test_dataset = tfds.load(name=DATASET_NAME, split=tfds.Split.TEST)\n",
        "test_dataset = test_dataset.map(read_images)\n",
        "test_dataset = test_dataset.map(normalize)\n",
        "test_dataset = test_dataset.repeat(1)\n",
        "test_dataset = test_dataset.batch(1024)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_cXisnd09--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_HEIGHT = None\n",
        "IMAGE_WIDTH = None\n",
        "IMAGE_DEPTH = None\n",
        "N_CLASSES = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GDT_FgwxK5A",
        "colab_type": "text"
      },
      "source": [
        "## Visualize some examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MPqqBCt0UQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axs = plt.subplots(nrows=3, ncols=12, constrained_layout=False, figsize=(22,4))\n",
        "\n",
        "data, labels = next(test_dataset.__iter__())\n",
        "\n",
        "IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH = data.shape[1:]\n",
        "\n",
        "for i, ax in enumerate(axs.flat):\n",
        "  ax.imshow(np.squeeze(np.reshape(data[i], (IMAGE_HEIGHT,IMAGE_WIDTH, IMAGE_DEPTH))))\n",
        "  \n",
        "plt.show()\n",
        "N_CLASSES=len(np.unique(labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xnMOXfW2Op7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"IMAGE HEIGHT:\",IMAGE_HEIGHT)\n",
        "print(\"IMAGE WIDTH:\",IMAGE_WIDTH)\n",
        "print(\"IMAGE DEPTH:\",IMAGE_DEPTH)\n",
        "print(\"NUMBER OF CLASSES:\",N_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pLM0LMrKzBC",
        "colab_type": "text"
      },
      "source": [
        "## Model Subclassing\n",
        "- Build a Python Class and extend the **tf.keras.Model** class provided by TF.\n",
        "- Define the model layers in the Class *Constructor*\n",
        "- Define the model's forward pass in the *call()* method\n",
        "\n",
        "## Define your model below\n",
        "- Define the number of filters for each conv layer\n",
        "- Define the size of the kernel for each conv layer\n",
        "- Try to add more layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xsNUnKTrLJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    # Define the layers here\n",
        "    super(Model, self).__init__()\n",
        "    self.conv1 = Conv2D(filters=..., kernel_size=..., padding=\"same\", strides=1, input_shape=(IMAGE_HEIGHT,IMAGE_WIDTH,IMAGE_DEPTH))\n",
        "    self.conv2 = Conv2D(filters=..., kernel_size=..., padding=\"same\", strides=1)\n",
        "    self.pool = MaxPool2D(pool_size=2, strides=2, padding=\"same\")\n",
        "    self.flat = Flatten()\n",
        "    self.probs = Dense(units=N_CLASSES, activation='softmax', name=\"output\")\n",
        "  \n",
        "  def call(self, x):\n",
        "    # Define the forward pass\n",
        "    net = self.conv1(x)\n",
        "    net = self.pool(net)\n",
        "    net = self.conv2(net)\n",
        "    net = self.pool(net)\n",
        "    net = self.flat(net)\n",
        "    net = self.probs(net)\n",
        "    return net\n",
        "  \n",
        "  def compute_output_shape(self, input_shape):\n",
        "    # You need to override this function if you want to use the subclassed model\n",
        "    # as part of a functional-style model.\n",
        "    # Otherwise, this method is optional.\n",
        "    shape = tf.TensorShape(input_shape).as_list()\n",
        "    shape[-1] = self.num_classes\n",
        "    return tf.TensorShape(shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2yt8XbbCxdEP",
        "colab": {}
      },
      "source": [
        "# create the model\n",
        "model = Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6lqhJIrxXam",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "\n",
        "- Both models (Sequential and Subclassing) can be trained using the fit() method.\n",
        "- The fit() method works either with:\n",
        "  - **tf.data.Dataset**\n",
        "  - **NumPy nd-arrays**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acbwLG0wifE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.compile(optimizer='adam',\n",
        "#               loss='sparse_categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# # train the model\n",
        "# model.fit(train_dataset, epochs=2, validation_data=test_dataset)\n",
        "\n",
        "# _ = model.evaluate(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIyv8yDMk9BL",
        "colab_type": "text"
      },
      "source": [
        "## Advanced Training loop\n",
        "\n",
        "If you want a clear understanding of what is going on during training, you can define the training loop by yourself using the **Gradient Tape**.\n",
        "\n",
        "- Forward pass\n",
        "- Loss function evaluation\n",
        "- Backward pass\n",
        "- Gradient descent step\n",
        "\n",
        "That is the best choice if:\n",
        "\n",
        "- You are doing research\n",
        "- You want to get a clear sense of Backprop and Gradient Descent steps.\n",
        "- You need to inspect your loss function w.r.t the weights or the gradient values.\n",
        "\n",
        "**More flexibility comes with an extra cost.**\n",
        "\n",
        "Best practices.\n",
        "- For Software Engineering, the fit() method has many more advantages \n",
        "- You can spot bugs faster\n",
        "- Code is written is a more standardized way"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W60L3hge0F0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the loss function and the optimizer\n",
        "cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okuqkiVJ3tWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the metrics and a loss function accumulator\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WQgsQfsz_KQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @tf.function\n",
        "def train_step(images, labels):\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    # forward pass\n",
        "    predictions = model(images)\n",
        "    \n",
        "    # compute the loss\n",
        "    loss = cross_entropy(tf.one_hot(labels, N_CLASSES), predictions)\n",
        "  \n",
        "  # get the gradients w.r.t the model's weights\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  \n",
        "  # perform a gradient descent step\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  \n",
        "  # accumulates the training loss and accuracy\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp7I9-UJz_O-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @tf.function\n",
        "def test_step(images, labels):\n",
        "  # Perform inference, and assess model accuracy \n",
        "  predictions = model(images)\n",
        "  t_loss = cross_entropy(tf.one_hot(labels, N_CLASSES), predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uli5-yTOz_SF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(2):\n",
        "  start = time.time()\n",
        "  for x_batch, y_batch in train_dataset:\n",
        "    train_step(x_batch, y_batch)\n",
        "    \n",
        "  end = time.time()-start\n",
        "  \n",
        "  # evaluate \n",
        "  for test_images, test_labels in test_dataset:\n",
        "    test_step(test_images, test_labels)\n",
        "\n",
        "  template = 'Epoch {}, Loss: {:0.2f}, Accuracy: {:0.2f}, Test Loss: {:0.2f}, Test Accuracy: {:0.2f}, Time taken for epoch is {:0.2f} sec'\n",
        "  print (template.format(epoch+1,\n",
        "                         train_loss.result(),\n",
        "                         train_accuracy.result()*100,\n",
        "                         test_loss.result(),\n",
        "                         test_accuracy.result()*100,\n",
        "                         end))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLuclmRp1cMN",
        "colab_type": "text"
      },
      "source": [
        "## Extracting Performance of your EagerCode\n",
        "\n",
        "- If you choose to train your model using Gradient Tape, you will notice a substantial decrease in performance\n",
        "\n",
        "- In TF 2.0 you can take advantage of Graph performance by using *tf.function*\n",
        "\n",
        "- If you decorate a python function with **tf.function**, TF will take your function and convert it to a TF high-performance abstraction\n",
        "\n",
        "**Try to decorate the training step function with with tf.function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rl_ecGgYu0GC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = []\n",
        "labels = []\n",
        "for test_images, test_labels in test_dataset:\n",
        "  probabilities = model(test_images.numpy())\n",
        "  predictions.extend(tf.argmax(probabilities, axis=1))\n",
        "  labels.extend(test_labels.numpy())\n",
        "  \n",
        "classes=[\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
        "plot_confusion_matrix(labels, predictions, classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dZNAMJXr7aK",
        "colab_type": "text"
      },
      "source": [
        "## Save and Restore Models\n",
        "\n",
        "- Single API to save and load models - The SavedModel\n",
        "- You can also save keras models using (HDF5 format)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-AvrR8xsDU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# serialize your model to a SavedModel object\n",
        "# It includes the entire graph, all variables and weights\n",
        "try:\n",
        "  model.save('/tmp/model', save_format='tf')\n",
        "except NotImplementedError:\n",
        "  tf.keras.experimental.export_saved_model(model, '/tmp/model')\n",
        "  \n",
        "!ls /tmp/model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFb2BqCbYzvb",
        "colab_type": "text"
      },
      "source": [
        "## Load the Saved Model and Reevaluate it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx6oKnNzjFCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load your saved model\n",
        "model = tf.keras.models.load_model('/tmp/model')\n",
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvCXDPpxkhVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = []\n",
        "labels = []\n",
        "for test_images, test_labels in test_dataset:\n",
        "  probabilities = model(test_images.numpy())\n",
        "  predictions.extend(tf.argmax(probabilities, axis=1))\n",
        "  labels.extend(test_labels.numpy())\n",
        "  \n",
        "classes=[\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
        "plot_confusion_matrix(labels, predictions, classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1oyi-Ap29AL",
        "colab_type": "text"
      },
      "source": [
        "## Converting to TF Lite\n",
        "\n",
        "- SavedModels are integrated with the Tensorflow ecosystem.\n",
        "- You can deploy a SavedModel to many different devices like Raspberry Pi, Edge TPUs or your phone.\n",
        "- You can do post-processing quantization with the TFLiteConverter\n",
        "- Set the optimizations flag to \"OPTIMIZE_FOR_SIZE\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1iostfpsDyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a TF Lite converter \n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# performs model quantization to reduce the size of the model and improve latency\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "\n",
        "tflite_model = converter.convert()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftleVjEKsD9y",
        "colab_type": "text"
      },
      "source": [
        "## Converting to Tensorflow.js"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28PKeDfPzqxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOE-nMMriOqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow==2.0.0-beta1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p07CQ1zoSkKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEPKabPmI6wa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tensorflowjs_converter --version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kAbeiu_XIuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tensorflowjs_converter \\\n",
        "    --input_format=tf_saved_model \\\n",
        "    --saved_model_tags=serve \\\n",
        "    --output_format=tfjs_graph_model \\\n",
        "    /tmp/model \\\n",
        "    /tmp/web_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfrYC0QmTCXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}